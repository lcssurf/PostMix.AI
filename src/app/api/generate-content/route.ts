export const maxDuration = 300; // 60 segundos (seu plano Vercel Pro permite)

import { NextResponse } from "next/server";
import OpenAI from "openai";
import { z } from "zod";

const openai = new OpenAI({
  apiKey: process.env.OPENROUTER_API_KEY!,
  baseURL: "https://openrouter.ai/api/v1",
  defaultHeaders: {
    "HTTP-Referer": "https://postmix.zanapp.com.br",
    "X-Title": "PostMix.AI",
  },
});

const RequestSchema = z.object({
  referenceUsername: z.string(),
  referenceProfile: z.object({
    full_name: z.string().optional(),
    biography: z.string().optional(),
    followers: z.number().optional(),
    profile_url: z.string().optional(),
  }),
  selectedPosts: z.array(
    z.object({
      caption: z.string(),
      likes: z.number().optional(),
      comments: z.number().optional(),
      datetime: z.string().optional(),
      url: z.string().optional(),
      image_url: z.string().nullable().optional(),
      video_url: z.string().nullable().optional(),
    })
  ),
  goal: z.string(),
  niche: z.string(),
  audience: z.string(),
  tone: z.string(),
  format: z.string(),
});

export async function POST(req: Request) {
  console.log("üìù Iniciando gera√ß√£o de conte√∫do... ", new Date().toISOString());
  
  try {
    const body = await req.json();
    const {
      referenceUsername,
      referenceProfile,
      selectedPosts,
      goal,
      niche,
      audience,
      tone,
      format,
    } = RequestSchema.parse(body);

    console.log("üìù Dados recebidos:", {
      "Nome de Usu√°rio de Refer√™ncia": referenceUsername,
      "Perfil de Refer√™ncia": referenceProfile,
      "Posts Selecionados": selectedPosts,
      "Objetivo": goal,
      "Nicho": niche,
      "P√∫blico-Alvo": audience,
      "Tom": tone,
      "Formato": format,
    });

    function getMediaType(url: string | undefined): string {
      if (!url) return "unknown";
      const extension = url.split('.').pop()?.toLowerCase();
      if (!extension) return "unknown";

      const imageExtensions = ["jpg", "jpeg", "png", "gif", "webp"];
      const videoExtensions = ["mp4", "mov", "avi", "mkv", "webm"];

      if (imageExtensions.includes(extension)) return "image";
      if (videoExtensions.includes(extension)) return "video";

      return "unknown";
    }

    selectedPosts.forEach((post) => {
      const mediaType = getMediaType(post.url);
      console.log(`Post URL: ${post.url}, Media Type: ${mediaType}`);
    });

    const postsResumo = selectedPosts
      .map((post, i) => {
        const midia = `M√≠dia (Imagem ou V√≠deo): ${post?.url}`
        return `# POST ${i + 1}\n- LEGENDA: "${post.caption.slice(0, 300)}"\n- ENG. ‚ù§Ô∏è ${post.likes || 0} | üí¨ ${post.comments || 0}\n- ${midia}\n`;
      })
      .join("\n");

    const hasManyEmptyCaptions = selectedPosts.filter(p => p.caption === "Sem legenda").length > 1;

    const prompt = `
<expert_prompt>
VOC√ä √â UM AGENTE CRIATIVO DE ALTO N√çVEL, ESPECIALIZADO EM CONTE√öDO PARA INSTAGRAM, DOMINANDO O NICHO DE **${niche.toUpperCase()}**.

SEU OBJETIVO √â TRANSFORMAR INSIGHTS DE POSTS REAIS EM UM √öNICO CONTE√öDO FINAL IMPACTANTE, COESO E PRONTO PARA POSTAGEM.

## ETAPAS DO SEU RACIOC√çNIO (CHAIN OF THOUGHTS):
1. COMPREENDA o perfil analisado e os temas recorrentes dos posts.
2. IDENTIFIQUE padr√µes de estilo, linguagem e engajamento.
3. CRIE um conte√∫do original que respeite o tom, formato e objetivo indicados.
4. ESTRUTURE a resposta diretamente no formato solicitado, SEM explica√ß√µes adicionais.

## PERFIL DE REFER√äNCIA:
- Nome: ${referenceUsername || "N√£o dispon√≠vel"}
- Bio: ${referenceProfile.biography || "N√£o dispon√≠vel"}
- Seguidores: ${referenceProfile.followers || "?"}
- Perfil: ${referenceProfile.profile_url || "N√£o informado"}

## RESUMO DOS POSTS DE REFER√äNCIA:
${postsResumo}

## INSTRU√á√ïES CR√çTICAS:
üéØ Objetivo: ${goal}
üß† P√∫blico-alvo: ${audience}
üéôÔ∏è Tom desejado: ${tone}
üì≤ Formato solicitado: ${format.toUpperCase()}
${hasManyEmptyCaptions ? "Observa√ß√£o: v√°rios posts est√£o sem legenda. Interprete o estilo e objetivo com base na m√≠dia e perfil." : ""}

## SA√çDA ESPERADA:
- SE **Reels**: Roteiro dividido por blocos de tempo (ex: 0‚Äì5s, 5‚Äì10s...), de no m√≠nimo 1 minuto, incluindo:
  ‚Ä¢ Fala ou narra√ß√£o
  ‚Ä¢ Texto na tela
  ‚Ä¢ Sugest√µes visuais
  ‚Ä¢ M√∫sica/trilha recomendada

- SE **Carrossel**: 
  ‚Ä¢ Slide 1: T√≠tulo chamativo
  ‚Ä¢ Slides 2+: Conte√∫do sequencial com storytelling
  ‚Ä¢ Slide final: CTA claro e poss√≠vel hashtag

- SE **Legenda**:
  ‚Ä¢ Texto envolvente, cativante, com gatilho emocional
  ‚Ä¢ Final com CTA e hashtags

‚ö†Ô∏è NUNCA forne√ßa explica√ß√µes ou varia√ß√µes alternativas.
‚úÖ ENTREGUE APENAS O CONTE√öDO FINAL, PRONTO PARA PUBLICA√á√ÉO.
</expert_prompt>
    `.trim();

    // üëá Tentativa com Qwen
    try {

      const images = selectedPosts
        .filter((post) => {
          const mediaType = getMediaType(post.url);
          return mediaType === "image";
        })
        .map((post) => post.url);

        const contentToSend = images.length === 0 
          ? prompt 
          : [
          {
            type: 'text',
            text: prompt,
          },
          ...images.map((url) => ({
            type: 'image_url',
            text: `${url}`,
          })),
            ];

        const serializedContent = Array.isArray(contentToSend)
          ? JSON.stringify(contentToSend)
          : contentToSend;

        const completion = await openai.chat.completions.create({
          // model: "meta-llama/llama-3.1-8b-instruct:free",
          model:"google/gemini-2.5-pro-exp-03-25:free",
          messages: [
            { 
          role: "user", 
          content: serializedContent 
            }
          ],
          temperature: 2,
          max_tokens: 50000,
        });

      const caption = completion.choices[0]?.message?.content?.trim();


      if (!caption) throw new Error("Resposta da IA veio vazia.");

      console.log(new Date().toISOString(), "üìù Resposta da IA:", caption);
      

      return NextResponse.json({
        content: [
          {
            caption,
            referencePostUrls: selectedPosts.map((p) => p.url),
          },
        ],
      });
      // Para debug, retorna o raw da resposta da IA
      // return NextResponse.json({ raw: completion });

    } catch (fallbackError) {
      console.warn("‚ö†Ô∏è Falha com modelo Qwen. Tentando fallback com GPT-4o...");

      const gptFallback = await openai.chat.completions.create({
        model: "qwen/qwen2.5-vl-72b-instruct:free",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
        max_tokens: 1200,
      });

      const caption = gptFallback.choices[0]?.message?.content?.trim();

      if (!caption) throw new Error("Fallback GPT-4o tamb√©m falhou.");

      return NextResponse.json({
        content: [
          {
            caption,
            referencePostUrls: selectedPosts.map((p) => p.url),
          },
        ],
      });
    }
  } catch (err: any) {
    console.error("‚ùå Erro na gera√ß√£o:", err);
    return NextResponse.json(
      { error: err.message || "Erro interno" },
      { status: 500 }
    );
  }
}
