import { NextResponse } from "next/server";
import OpenAI from "openai";
import { z } from "zod";

export const maxDuration = 300; // 5 minutos

const openai = new OpenAI({
  apiKey: process.env.OPENROUTER_API_KEY!,
  baseURL: "https://openrouter.ai/api/v1",
  defaultHeaders: {
    "HTTP-Referer": "https://postmix.zanapp.com.br",
    "X-Title": "PostMix.AI",
  },
});

const RequestSchema = z.object({
  referenceUsername: z.string(),
  referenceProfile: z.object({
    full_name: z.string().optional(),
    biography: z.string().optional(),
    followers: z.number().optional(),
    profile_url: z.string().optional(),
  }),
  selectedPosts: z.array(
    z.object({
      caption: z.string(),
      transcription: z.array(z.string()).optional(),
      likes: z.number().optional(),
      comments: z.number().optional(),
      datetime: z.string().optional(),
      url: z.string().optional(),
      image_url: z.string().nullable().optional(),
      video_url: z.string().nullable().optional(),
    })
  ),
  goal: z.string(),
  niche: z.string(),
  audience: z.string(),
  tone: z.string(),
  format: z.string(),
});

export async function POST(req: Request) {
  console.log("ğŸ“ Iniciando geraÃ§Ã£o de conteÃºdo...", new Date().toISOString());

  try {
    const body = await req.json();
    const {
      referenceUsername,
      referenceProfile,
      selectedPosts,
      goal,
      niche,
      audience,
      tone,
      format,
    } = RequestSchema.parse(body);

    console.log("ğŸ“¦ Dados recebidos:", { referenceUsername, selectedPosts });

    const postsResumo = selectedPosts.map((post, i) => {
      const texto = post.transcription
        ? post.transcription.join(" ").slice(0, 300)
        : post.caption.slice(0, 300);

      return `# POST ${i + 1}
- Texto: "${texto}"
- â¤ï¸ ${post.likes || 0} | ğŸ’¬ ${post.comments || 0}
- Link: ${post.url || "nÃ£o informado"}`;
    }).join("\n");

    const hasManyEmptyCaptions = selectedPosts.filter(p => p.caption === "Sem legenda").length > 1;

    const prompt = `
<expert_prompt>
VocÃª Ã© um especialista em criaÃ§Ã£o de conteÃºdo de alto impacto para Instagram, com foco no nicho de **${niche.toUpperCase()}**.

Utilize as transcriÃ§Ãµes e legendas fornecidas para criar um novo conteÃºdo Ãºnico, original e adaptado conforme as orientaÃ§Ãµes abaixo.

## Perfil de ReferÃªncia:
- Nome: ${referenceUsername}
- Bio: ${referenceProfile.biography || "NÃ£o disponÃ­vel"}
- Seguidores: ${referenceProfile.followers || "?"}
- Link: ${referenceProfile.profile_url || "NÃ£o informado"}

## Resumo dos Posts de ReferÃªncia:
${postsResumo}

## InstruÃ§Ãµes:
ğŸ¯ Objetivo: ${goal}
ğŸ§  PÃºblico-Alvo: ${audience}
ğŸ™ï¸ Tom: ${tone}
ğŸ“² Formato: ${format.toUpperCase()}
${hasManyEmptyCaptions ? "âš¡ AtenÃ§Ã£o: VÃ¡rios posts sem legenda. Foque nas mÃ­dias e no estilo geral do perfil." : ""}

## Regras:
- NÃƒO explique o que estÃ¡ fazendo.
- NÃƒO ofereÃ§a variaÃ§Ãµes alternativas.
- Gere apenas o conteÃºdo final, pronto para publicaÃ§Ã£o.

## Estrutura Esperada:
- Para **REELS**: roteiro dividido em blocos de tempo (ex: 0â€“5s, 5â€“10s...), fala, texto na tela, sugestÃµes visuais e mÃºsica.
- Para **CARROSSEL**: slides em sequÃªncia com storytelling e CTA final.
- Para **LEGENDA**: texto emocional e gatilhos + hashtags.

</expert_prompt>
    `.trim();

    let caption: string | null = null;

    try {
      console.log("ğŸš€ Tentando gerar com modelo principal");
      const completion = await openai.chat.completions.create({
        model: "meta-llama/llama-4-maverick:free",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
        max_tokens: 4000,
      });

      caption = completion.choices[0]?.message?.content?.trim() ?? null;
      if (!caption) throw new Error("Resposta da IA veio vazia.");

    } catch (error) {
      console.warn("âš ï¸ A geraÃ§Ã£o principal falhou. Tentando fallback com outro modelo...");

      const fallback = await openai.chat.completions.create({
        model: "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
        max_tokens: 4000,
      });

      caption = fallback.choices[0]?.message?.content?.trim() ?? null;
      if (!caption) throw new Error("Fallback tambÃ©m falhou.");
    }

    console.log("âœ… ConteÃºdo gerado:", caption);

    return NextResponse.json({
      content: [
        {
          caption,
          referencePostUrls: selectedPosts.map((p) => p.url),
        },
      ],
    });

  } catch (err: any) {
    console.error("âŒ Erro na geraÃ§Ã£o:", err);
    return NextResponse.json(
      { error: err.message || "Erro interno" },
      { status: 500 },
    );
  }
}
