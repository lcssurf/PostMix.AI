export const runtime = "nodejs"; // evitar timeout do edge (se for Next.js app route)
export const config = { maxDuration: 60 }; // permite at√© 60s no plano Pro

import { NextResponse } from "next/server";
import OpenAI from "openai";
import { z } from "zod";

const openai = new OpenAI({
  apiKey: process.env.OPENROUTER_API_KEY!,
  baseURL: "https://openrouter.ai/api/v1",
  defaultHeaders: {
    "HTTP-Referer": "https://postmix.zanapp.com.br",
    "X-Title": "PostMix.AI",
  },
});

const RequestSchema = z.object({
  referenceUsername: z.string(),
  referenceProfile: z.object({
    full_name: z.string().optional(),
    biography: z.string().optional(),
    followers: z.number().optional(),
    profile_url: z.string().optional(),
  }),
  selectedPosts: z.array(
    z.object({
      caption: z.string(),
      likes: z.number().optional(),
      comments: z.number().optional(),
      datetime: z.string().optional(),
      url: z.string().optional(),
      image_url: z.string().nullable().optional(),
      video_url: z.string().nullable().optional(),
    })
  ),
  goal: z.string(),
  niche: z.string(),
  audience: z.string(),
  tone: z.string(),
  format: z.string(),
});

export async function POST(req: Request) {
  console.log("üìù Iniciando gera√ß√£o de conte√∫do... ", new Date().toISOString());
  
  try {
    const body = await req.json();
    const {
      referenceUsername,
      referenceProfile,
      selectedPosts,
      goal,
      niche,
      audience,
      tone,
      format,
    } = RequestSchema.parse(body);

    const postsResumo = selectedPosts
      .map((post, i) => {
        const midia = post.video_url
          ? `üéûÔ∏è V√≠deo: ${post.video_url}`
          : post.image_url
          ? `üñºÔ∏è Imagem: ${post.image_url}`
          : "Sem m√≠dia";
        return `# POST ${i + 1}\n- LEGENDA: "${post.caption.slice(0, 300)}"\n- ENG. ‚ù§Ô∏è ${post.likes || 0} | üí¨ ${post.comments || 0}\n- ${midia}\n`;
      })
      .join("\n");

    const hasManyEmptyCaptions = selectedPosts.filter(p => p.caption === "Sem legenda").length > 1;

    const prompt = `
<expert_prompt>
VOC√ä √â UM AGENTE CRIATIVO DE ALTO N√çVEL, ESPECIALIZADO EM CONTE√öDO PARA INSTAGRAM, DOMINANDO O NICHO DE **${niche.toUpperCase()}**.

SEU OBJETIVO √â TRANSFORMAR INSIGHTS DE POSTS REAIS EM UM √öNICO CONTE√öDO FINAL IMPACTANTE, COESO E PRONTO PARA POSTAGEM.

## ETAPAS DO SEU RACIOC√çNIO (CHAIN OF THOUGHTS):
1. COMPREENDA o perfil analisado e os temas recorrentes dos posts.
2. IDENTIFIQUE padr√µes de estilo, linguagem e engajamento.
3. CRIE um conte√∫do original que respeite o tom, formato e objetivo indicados.
4. ESTRUTURE a resposta diretamente no formato solicitado, SEM explica√ß√µes adicionais.

## PERFIL DE REFER√äNCIA:
- Nome: ${referenceProfile.full_name || referenceUsername}
- Bio: ${referenceProfile.biography || "N√£o dispon√≠vel"}
- Seguidores: ${referenceProfile.followers || "?"}
- Perfil: ${referenceProfile.profile_url || "N√£o informado"}

## RESUMO DOS POSTS DE REFER√äNCIA:
${postsResumo}

## INSTRU√á√ïES CR√çTICAS:
üéØ Objetivo: ${goal}
üß† P√∫blico-alvo: ${audience}
üéôÔ∏è Tom desejado: ${tone}
üì≤ Formato solicitado: ${format.toUpperCase()}
${hasManyEmptyCaptions ? "Observa√ß√£o: v√°rios posts est√£o sem legenda. Interprete o estilo e objetivo com base na m√≠dia e perfil." : ""}

## SA√çDA ESPERADA:
- SE **Reels**: Roteiro dividido por blocos de tempo (ex: 0‚Äì5s, 5‚Äì10s...), incluindo:
  ‚Ä¢ Fala ou narra√ß√£o
  ‚Ä¢ Texto na tela
  ‚Ä¢ Sugest√µes visuais
  ‚Ä¢ M√∫sica/trilha recomendada

- SE **Carrossel**: 
  ‚Ä¢ Slide 1: T√≠tulo chamativo
  ‚Ä¢ Slides 2+: Conte√∫do sequencial com storytelling
  ‚Ä¢ Slide final: CTA claro e poss√≠vel hashtag

- SE **Legenda**:
  ‚Ä¢ Texto envolvente, cativante, com gatilho emocional
  ‚Ä¢ Final com CTA e hashtags

‚ö†Ô∏è NUNCA forne√ßa explica√ß√µes ou varia√ß√µes alternativas.
‚úÖ ENTREGUE APENAS O CONTE√öDO FINAL, PRONTO PARA PUBLICA√á√ÉO.
</expert_prompt>
    `.trim();

    // üëá Tentativa com Qwen
    try {
      const completion = await openai.chat.completions.create({
        model: "meta-llama/llama-3.1-8b-instruct:free",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
        max_tokens: 1200,
      });

      const caption = completion.choices[0]?.message?.content?.trim();


      if (!caption) throw new Error("Resposta da IA veio vazia.");

      console.log(new Date().toISOString(), "üìù Resposta da IA:", caption);
      

      // return NextResponse.json({
      //   content: [
      //     {
      //       caption,
      //       referencePostUrls: selectedPosts.map((p) => p.url),
      //     },
      //   ],
      // });
      // Para debug, retorna o raw da resposta da IA
      return NextResponse.json({ raw: completion });

    } catch (fallbackError) {
      console.warn("‚ö†Ô∏è Falha com modelo Qwen. Tentando fallback com GPT-4o...");

      const gptFallback = await openai.chat.completions.create({
        model: "qwen/qwen2.5-vl-72b-instruct:free",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
        max_tokens: 1200,
      });

      const caption = gptFallback.choices[0]?.message?.content?.trim();

      if (!caption) throw new Error("Fallback GPT-4o tamb√©m falhou.");

      return NextResponse.json({
        content: [
          {
            caption,
            referencePostUrls: selectedPosts.map((p) => p.url),
          },
        ],
      });
    }
  } catch (err: any) {
    console.error("‚ùå Erro na gera√ß√£o:", err);
    return NextResponse.json(
      { error: err.message || "Erro interno" },
      { status: 500 }
    );
  }
}
